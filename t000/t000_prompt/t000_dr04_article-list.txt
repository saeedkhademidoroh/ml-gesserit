Computing Machinery and Intelligence (Alan Turing, 1950)
The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain (Frank Rosenblatt, 1958)
A Logical Calculus of the Ideas Immanent in Nervous Activity (McCulloch & Pitts, 1943)
Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position (Kunihiko Fukushima, 1980)
Eigenfaces for Recognition (Turk & Pentland, 1991)
Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection (Belhumeur, Hespanha, Kriegman, 1997)
Object Recognition from Local Scale-Invariant Features (David Lowe, 2004)
Rapid Object Detection using a Boosted Cascade of Simple Features (Viola & Jones, 2001)
A Training Algorithm for Optimal Margin Classifiers (Boser, Guyon, Vapnik, 1992)
Induction of Decision Trees (J. Ross Quinlan, 1986)
Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference (Judea Pearl, 1988)
Nearest neighbor pattern classification (Cover & Hart, 1967)
Backpropagation Applied to Handwritten Zip Code Recognition (LeCun et al., 1989)
A Fast Learning Algorithm for Deep Belief Nets (Hinton, Osindero, Teh, 2006)
ImageNet Classification with Deep Convolutional Neural Networks (Krizhevsky, Sutskever, Hinton, 2012)
Very Deep Convolutional Networks for Large-Scale Image Recognition (Simonyan & Zisserman, 2014)
Going Deeper with Convolutions (Szegedy et al., 2014)
Deep Residual Learning for Image Recognition (He, Zhang, Ren, Sun, 2015)
EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (Tan & Le, 2019)
An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (Dosovitskiy et al., 2020)
Efficient Estimation of Word Representations in Vector Space (Mikolov et al., 2013)
GloVe: Global Vectors for Word Representation (Pennington, Socher, Manning, 2014)
Sequence to Sequence Learning with Neural Networks (Sutskever, Vinyals, Le, 2014)
Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau, Cho, Bengio, 2015)
Attention Is All You Need (Vaswani et al., 2017)
Improving Language Understanding by Generative Pre-Training (Radford et al., 2018)
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al., 2018)
Language Models are Unsupervised Multitask Learners (Radford et al., 2019)
Language Models are Few-Shot Learners (Brown et al., 2020)
DeepFace: Closing the Gap to Human-Level Performance in Face Verification (Taigman et al., Facebook, 2014)
FaceNet: A Unified Embedding for Face Recognition and Clustering (Schroff, Kalenichenko, Philbin, Google, 2015)
DeepID3: Face Recognition with Very Deep Neural Networks (Sun et al., 2015)
SphereFace: Deep Hypersphere Embedding for Face Recognition (Liu et al., 2017)
CosFace: Large Margin Cosine Loss for Deep Face Recognition (Wang et al., 2018)
ArcFace: Additive Angular Margin Loss for Deep Face Recognition (Deng et al., 2019)
Learning from Delayed Rewards (Watkins, 1989)
Playing Atari with Deep Reinforcement Learning (Mnih et al., DeepMind, 2013/2015)
Understanding the difficulty of training deep feedforward neural networks (Glorot & Bengio, 2010)
Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (He et al., 2015)
Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (Ioffe & Szegedy, 2015)
Dropout: A Simple Way to Prevent Neural Networks from Overfitting (Srivastava, Hinton, et al., 2014)
Adam: A Method for Stochastic Optimization (Kingma & Ba, 2014)
Decoupled Weight Decay Regularization (Loshchilov & Hutter, 2017/2019)
Rethinking the Inception Architecture for Computer Vision (Szegedy et al., 2016)
mixup: Beyond Empirical Risk Minimization (Zhang et al., 2017)
CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features (Yun et al., 2019)
Deep Networks with Stochastic Depth (Huang et al., 2016)
AutoAugment: Learning Augmentation Strategies From Data (Cubuk et al., 2019)
Sharpness-Aware Minimization for Efficiently Improving Generalization (Foret et al., 2020)
Transformer-Based Auxiliary Loss for Age-Invariant Face Recognition (Mahdi Abbasi, Sobhan Shafiei, Pooya Salehi, Akram Gholamzadeh, Mohammad H. Rohban, Mahdi Eftekhari, 2025)
Review of Demographic Fairness in Face Recognition (Ketan Kotwal, Sebastien Marcel, 2025)
VariFace: Fair and Diverse Synthetic Dataset Generation for Face Recognition (Michael Yeung, Toya Teramoto, Songtao Wu, et al., 2024)
FaceXFormer: A Unified Transformer for Facial Analysis (Kartik Narayan, Vibashan VS, Rama Chellappa, Vishal M. Patel, 2025)
Face-LLaVA: Facial Expression and Attribute Understanding through Instruction Tuning (Ashutosh Chaubey, Xulang Guan, Mohammad Soleymani, 2025)
A Comprehensive Review of Face Recognition Techniques, Trends and Challenges (IEEE Access, 2024)
LLLMs: A Data-Driven Survey of Evolving Research on Limitations of Large Language Models (Aida Kostikova, Zhipin Wang, Deidamea Bajri, Ole Pütz, Benjamin Paaßen, Steffen Eger, 2025)
Birdie: Efficient State Space Models through Bidirectional Input Processing and Specialized Pre-Training Objective Mixtures (Posu Chen, Hitu Seth, Parijat Dube, et al., 2024)
From N-grams to Transformers and Back: A Comparative Behavioral Framework for Bias in Language Models (Debjanee Barua, Gaoge WANG, Elissa M. Redmiles, Michelle Mazurek, Wojtek Palubicki, 2025)
Advancing Reasoning in Large Language Models: Promising Methods and Approaches (Avinash Patil, Aryan Jadon, 2025)
Empowering LLMs with Logical Reasoning: A Comprehensive Survey (Fengxiang Cheng, Haoxuan Li, Fenrong Liu, Robert van Rooij, Kun Zhang, Zhouchen Lin, 2025)
Cross-Images Contrastive Decoding: Precise, Lossless Suppression of Language Priors in Large Vision-Language Models (Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng, 2025)
Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding (Kyungmin Min, Minbeom Kim, Kang-il Lee, Dongryeol Lee, Kyomin Jung, 2025)
ConKE: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning (Liyu Zhang, Weiqi Wang, Tianqing Fang, Yangqiu Song, 2025)
Multimodal Large Language Models Can Significantly Advance Scientific Reasoning (Jiahua Dong, Zhibin Gou, Yifu Geng, et al., 2025)
Large Multimodal Models for Low-Resource Languages: A Survey (Mohamed Abdalla, Muhammad Abdul-Mageed, et al., 2025)
Quantizing Large Language Models for Code Generation: A Differentiated Replication (Alessandro Giagnorio, Antonio Mastropaolo, Saima Afrin, Massimiliano Di Penta, Gabriele Bavota, 2025)
When Reasoning Meets Compression: Benchmarking Compressed Large Reasoning Models on Complex Reasoning Tasks (Nan Zhang, Yusen Zhang, Prasenjit Mitra, Rui Zhang, 2025)
ECViT: Efficient Convolutional Vision Transformer with Local-Attention and Multi-scale Stages (Zhoujie Qian, 2025)
UniViTAR: Unified Vision Transformer with Native Resolution (Limeng Qiao, et al., 2025)
Generative Physical AI in Vision: A Survey (Daochang Liu, Junyu Zhang, Anh-Dung Dinh, Eunbyung Park, Shichao Zhang, Ajmal Mian, Mubarak Shah, Chang Xu, 2025)
VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness (Large collaborative effort, 2025)
Controllable 3D Outdoor Scene Generation via Scene Graphs (Yiran Xing, Zhaoxiang Cai, et al., 2025)
Escaping the Big Data Paradigm in Self-Supervised Representation Learning from Images (Carlos Velez-García, Miguel Cazorla, Jorge Pomares, 2025)
UpStep: Unsupervised Parameter-efficient Source-free Post-pretraining (Ulas Gul, Oguz Kaan Yüksel, et al., 2025)
A Survey on Explainable Deep Reinforcement Learning (Zelei Cheng, Jiahao Yu, Xinyu Xing, 2025)
Video-Enhanced Offline RL (VeoRL): A Model-Based Approach (Yecheng Moon, et al., 2025)
Variational OOD State Correction for Offline Reinforcement Learning (Zicheng Zhang, et al., 2025)
Addressing Rotational Learning Dynamics in Multi-Agent Reinforcement Learning (Di-An Jan, et al., 2025)
Offline Multi-agent Reinforcement Learning via Score Decomposition (Lingheng Meng, et al., 2025)
A Shared Low-Rank Adaptation Approach to Personalized RLHF (Renpu Liu, Peng Wang, Donghao Li, Cong Shen, Jing Yang, 2025)
MA-RLHF: Reinforcement Learning from Human Feedback with Macro Actions (Yekun Chai, Haoran Sun, Huang Fang, Shuohuan Wang, Yu Sun, Hua Wu, 2025)
CORL: Clean Offline Reinforcement Learning (Authors of CORL library, presented at NeurIPS 2023)
ZeroFlow: Overcoming Catastrophic Forgetting is Easier than You Think (Tao Feng, Wei Li, Didi Zhu, Hangjie Yuan, Wendi Zheng, Dan Zhang, Jie Tang, 2025)
LORENZA: Enhancing Generalization in Low-Rank Gradient LLM Training and Fine-Tuning via Efficient Zeroth-Order Adaptive SAM Optimization (Yehonathan Refael, Iftach Arbel, Ofir Lindenbaum, Tom Tirer, 2025)
Deep Multi-Task Learning Has Low Amortized Intrinsic Dimensionality (Hossein Zakerinia, et al., 2025)
Survey on Generalization Theory for Graph Neural Networks (Kajetan Schweighofer, et al., 2025)
Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models (Yao Shu, Wenyang Hu, See-Kiong Ng, Bryan Kian Hsiang Low, Fei Richard Yu, 2024)
FedDDL: Federated Deconfounding and Debiasing Learning for Out-of-Distribution Generalization (Qi Zhuang, Ming-Chang Lee, Han Yu, et al., 2025)
FLTG: Byzantine-Robust Federated Learning via Angle-Based Defense and Non-IID-Aware Weighting (Jiahao Wang, et al., 2025)
Communication-efficient Vertical Federated Learning via Compressed Error Feedback (Pedro Valdeira, João Xavier, Cláudia Soares, Yuejie Chi, 2024)
A Statistical Case Against Empirical Human-AI Alignment (Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin, 2025)
SCHEME: Scalable CHannEl MixEr for Vision Transformers (Apostolos Modas et al., 2023)
An Exploratory Approach Towards Investigating and Explaining Vision Transformer and Transfer Learning for Brain Disease Detection (Md. Al Momin Rifat et al., 2023)
Vision Foundation Models in Medical Image Analysis: Advances and Challenges (Pengchen Liang, Bin Pu, Haishan Huang, Yiwei Li, Hualiang Wang, Weibo Ma, Qing Chang, 2025)
You Do Not Fully Utilize Transformer's Representation Capacity (Authors/Year Not Specified)
Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Gu, A., & Dao, T., 2023)
QLoRA: Efficient Finetuning of Quantized LLMs (Dettmers, T., Pagnoni, A., Holtzman, A., & Zettlemoyer, L., 2023)
Sparks of Artificial General Intelligence: Early experiments with GPT-4 (Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., Nori, H., Palangi, H., Ribeiro, M. T., & Zhang, Y., 2023)
Vision Transformers Need Registers (Darcet, T., Cord, M., Pérez-Pellitero, E., & Thome, N., 2024)
X-ray Imaging-driven Detection Network (XID-Net) (2024)
AdaFace: Quality Adaptive Margin for Deep Face Recognition (Kim, M., Jain, A. K., & Liu, X., 2022)
Image Recognition with Online Lightweight Vision Transformer: A Survey (2025)
Disentangled Source-Free Domain Adaptation (DSFDA) for Facial Expression Recognition (Sharafi et al., 2025)
The Llama 3 Herd of Models (Grattafiori, A., et al., 2024)
Gemma: Open Models Based on Gemini Research and Technology (Mesnard, T., et al. (Google team), 2024)
Why Larger Language Models Do In-context Learning Differently? (Min, Z., et al., 2024)
DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective (Peng, D., Zhou, Y., Chen, Q., Liu, J., Chen, J., & Qin, L., 2025)
A Survey of Large Language Models (Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., et al., 2023)
The Flan Collection: Designing Data and Methods for Effective Instruction Tuning (Longpre, S., Hou, L., Vu, T., Webson, A., Chung, H. W., Tay, Y., Zhou, D., Le, Q. V., Zoph, B., Wei, J., & Roberts, A., 2023)
LIMA: Less Is More for Alignment (Zhou, C., Liu, P., Xu, P., Iyer, S., Sun, J., Mao, Y., Ma, X., Efrat, A., Yu, P., Yu, L., et al., 2023)
Phi-3.5-Vision-Instruct (Microsoft, 2024)
Llama-3.2-11B-Vision-Instruct (Meta Platforms, 2024)
Pixtral-12B (Mistral AI, 2024)
Language Modeling for the Future of Finance: A Quantitative Survey into Metrics, Tasks, and Data Opportunities (Tatarinov, N., Sukhani, S., Shah, A., & Chava, S., 2025)
LLMs for Explainable AI: A Comprehensive Survey (Bilal, A., Ebert, D., & Lin, B., 2025)
Random Policy Enables In-Context Reinforcement Learning within Trust Horizons (2025)
Decision Pretrained Transformer (DPT) (Lee, K., et al., 2024)
Decision Importance Transformer (DIT) (Dong, Q., et al., 2024)
AutoConcierge (Zeng, Z., Zhang, R., Zhang, Y., Li, Y., & Nanas, N., 2024)
AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware Cross-domain Recommendations (Liu, J., Gu, S., Li, D., Zhang, G., Han, M., Gu, H., Zhang, P., Lu, T., Shang, L., & Gu, N., 2025)
RecMind: Large Language Model Powered Agent For Recommendation (Wang, Y., et al., 2023/2024)
Agent4Rec (Zhang, J., et al., 2024a)
LASER: LLM Agent with State-Space Exploration for Web Navigation (Ma, K., Zhang, H., Wang, H., Pan, X., Yu, W., & Yu, D., 2024)
CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models (Gong, P., Li, J., & Mao, J., 2024)
AVATAR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning (Wu, S., Zhao, S., et al., 2024)
USimAgent: Large Language Models for Simulating Search Users (Zhang, E., Wang, X., Gong, P., Lin, Y., & Mao, J., 2024)
A Survey of Large Language Model Empowered Agents for Recommendation and Search (Zhang, Y., Qiao, S., Zhang, J., Lin, T.-H., Gao, C., & Li, Y., 2025)
A Survey on LLM-powered Agents for Recommender Systems (Peng, Q., Liu, H., Huang, H., Yang, Q., & Shao, M., 2025)
Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web (CompWoB) (Furuta, H., Matsuo, Y., Faust, A., & Gur, I., 2024)
SlimLLM: An Effective and Fast Structured Pruning Method for Large Language Models (2024/2025)
MoRE: Mixture of Low-Rank Experts for Multi-Task Parameter-Efficient Fine-Tuning (2024/2025)
On the Challenges and Opportunities in Generative AI (Dellaferrera, G., et al., 2025)
BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models (Li, J., Li, D., Savarese, S., & Hoi, S., 2023)
InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning (Dai, W., Li, J., Li, D., Tiong, A. M., Zhao, J., Wang, W.,... & Hoi, S., 2023)
MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models (Zhu, D., Chen, J., Shen, X., Li, X., & Elhoseiny, M., 2023)
PaLM-E: An Embodied Multimodal Language Model (Driess, D., Xia, F., Sajjadi, M. S. M., Lynch, C., Chowdhery, A., Ichter, B.,... & Florence, P., 2023)
Visual Instruction Tuning (LLaVA) (Liu, H., Li, C., Wu, Q., & Lee, Y. J., 2023)
From Deep Learning to LLMs: A survey of AI in Quantitative Investment (arXiv)
MutBERT: Probabilistic Genome Representation Improves Genomics Foundation
Advancing Multimodal Large Language Models: Optimizing Prompt Engineering Strategies for Enhanced Performance (MDPI)
Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review (arXiv)
Multi-agents based User Values Mining for Recommendation (arXiv)
A Survey on Large Language Models in Multimodal Recommender Systems (Wu et al., 2025)